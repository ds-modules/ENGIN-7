{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# E7: Introduction to Computer Programming for Scientists and Engineers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each question, you will have to fill in one or more Python functions. We provide an autograder with a number of test cases that you can use to test your function. Note that the fact that your function works for all test cases thus provided does necessarily guarantee\n",
    "that it will work for all possible test cases relevant to the question. It is your responsibility\n",
    "to test your function thoroughly, to ensure that it will also work in situations not covered\n",
    "by the test cases provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Please run this cell, and do not modify the contets\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.seterr(all='ignore');\n",
    "# %run lab2_ag.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Getting familiar with image files\n",
    "\n",
    "A digital color image is a grid of colored cells called pixels (short for picture elements). When\n",
    "viewed together, the pixels form an image, as shown below.\n",
    "\n",
    "![](E7_Lab7_1.jpg)\n",
    "Figure 1: MATLAB logo at very low resolution: it consists of a grid of color pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The color of a pixel is represented with three numbers between 0 and 1. The three\n",
    "numbers correspond to the intensity of red, green, and blue, which are combined to form the\n",
    "final color. For example [0, 0, 0] is black, [1, 1, 1] is white, [1, 0, 0] is pure red, and [1, 1, 0]\n",
    "is yellow.\n",
    "\n",
    "A gray pixel is a pixel in which the red, blue, and green values are equal. For example,\n",
    "[0.7, 0.7, 0.7] is a gray pixel, but [0, 0.7, 0.7] is not. When converting a color image to a\n",
    "gray-scale image, one has to define the pixels of the gray-scale image such that their value is\n",
    "equal to the average value of the red, green, and blue intensities of that pixel in the original\n",
    "color image. For example, the pixel [0.7, 0.5, 0.3] in a color image becomes [0.5, 0.5, 0.5] on\n",
    "its gray-scale conversion.\n",
    "\n",
    "A binary image is an image that has only black and white pixels. Such an image can be\n",
    "obtained from a gray scale image using a predefined threshold value (a number between 0\n",
    "and 1). Each pixel of the image serving as a base that has a gray scale value smaller than or\n",
    "equal to the threshold is converted to a black pixel. The other pixels are converted to white\n",
    "pixels.\n",
    "\n",
    "MATLAB logo as: a gray-scale image | a binary image with threshold = 0.6\n",
    "- | - \n",
    "![](E7_Lab7_2.jpg) | ![](E7_Lab7_3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import an image file into Python, use the following command:\n",
    "\n",
    "```Python\n",
    "img = double(imread('my_image.png'))/255;\n",
    "```\n",
    "\n",
    "Note that the command imread outputs an array containing integers between 0 and 255 (by\n",
    "default pixels components are coded on one byte (1 byte = 8 bits); thus there are $2^8 = 256$\n",
    "different possible values). In order to be able to performs operations on the pixels, we convert\n",
    "the output to `double`, and divide by 255 to obtain values varying between 0 and 1. To open\n",
    "the image file this way, `'my_image.png'` should be in your current working directory. The\n",
    "output of the command, img, is a `N x M x 3` array. `N` and `M` are the number of pixels per\n",
    "column and row, respectively. For each pixel (i,j), the red, green, and blue values are stored\n",
    "in `img(i,j,1)`, `img(i,j,2)`, `img(i,j,3)`, respectively. Note that the command imread can\n",
    "handle several types of image files extensions: .bmp, .jpg, .gif, .tiff, ..., and many more.\n",
    "\n",
    "You can tell MATLAB to display the image stored in an array img in a \f",
    "gure window\n",
    "using the command:\n",
    "\n",
    "```Python\n",
    "image(img)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Red, Green, Blue Decomposition\n",
    "\n",
    "Write a function `myRGBDecomposition(img)`\n",
    "that takes a `N x M x 3` array `img` (representing a color image) as an input and returns three\n",
    "`N x M x 3` arrays corresponding, respectively, with the red, green and blue pixels of img.\n",
    "Check your outputs using the command:\n",
    "\n",
    "```Python\n",
    "image(img_red+img_green+img_blue);\n",
    "```\n",
    "\n",
    "You should observe the same image as the one stored in the input array `img`, since adding\n",
    "red, green and blue pixels reconstructs the original image.\n",
    "\n",
    "You are provided with a picture of the Sather Tower on bCourses (`'sather.jpg'`) as a\n",
    "test case, but your function should work on any image (try it out on your favorite images!).\n",
    "\n",
    "![](E7_Lab7_4.jpg)\n",
    "Figure 3: The world-famous Sather Tower (Go Bears!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Test Case:\n",
    "```Python\n",
    "img = double(imread('sather.jpg'))/255;\n",
    "[img_red, img_green, img_blue] = myRGBDecomposition(img);\n",
    "```\n",
    "\n",
    "image(img_red) | image(img_green) | image(img_blue)\n",
    "- | - | -\n",
    "![](E7_Lab7_5.jpg) | ![](E7_Lab7_6.jpg) | ![](E7_Lab7_7.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Gray Scale\n",
    "\n",
    "Write a Python function `myGrayConverter(img)` that takes a `N x M x 3` array img (representing a color image) as an input and returns a NxMx3 array representing the corresponding gray scale image. \n",
    "\n",
    "You are NOT allowed to use the built-in Python function rgb2gray.\n",
    "\n",
    "Test Case:\n",
    "```Python\n",
    ">> img = double(imread('sather.jpg'))/255;\n",
    ">> img_gray = myGrayConverter(img);\n",
    ">> image(img_gray)\n",
    "```\n",
    "![](E7_Lab7_8.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Black & White\n",
    "\n",
    "Write a function `myBinaryConverter(img_gray, threshold)`\n",
    "that takes an `N x M x 3` array `img_gray` (representing a gray scale image) and a scalar double between 0 and 1 threshold, and returns an `N x M x 3` array representing\n",
    "the corresponding binary image. \n",
    "\n",
    "You are NOT allowed to use the built-in MATLAB function im2bw.\n",
    "\n",
    "Test Case:\n",
    "```Python\n",
    ">> img = double(imread('sather.jpg'))/255;\n",
    ">> img_gray = myGrayConverter(img);\n",
    ">> img_binary = myBinaryConverter(img_gray, 0.5);\n",
    ">> image(img_binary)\n",
    "```\n",
    "![](E7_Lab7_9.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4: Filters\n",
    "\n",
    "Many smartphone applications or digital cameras offer the possibility to apply filters to your\n",
    "pictures. Most of them are actually nothing more than a manipulation of the red, green\n",
    "and blue pixels of the initial image. For example, a vintage filter can be obtained using the\n",
    "following transformation for every pixel `(i,j)` of an image:\n",
    "\n",
    "$$\\begin{cases}\n",
    "redNew &= 0:393 * redOld + 0:769 * greenOld + 0:189 * blueOld \\\\\n",
    "greenNew &= 0:349 * redOld + 0:686 * greenOld + 0:168 * blueOld \\\\\n",
    "blueNew &= 0:272 * redOld + 0:534 * greenOld + 0:131 * blueOld\n",
    "\\end{cases}$$\n",
    "\n",
    "redOld, greenOld and blueOld represent the red, green and blue pixels of the initial image.\n",
    "redNew, greenNew and blueNew represent the red, green and blue pixels of the new image.\n",
    "\n",
    "Write a function `myVintageFilter(img)` that takes a `N x M x 3` array `img` (representing a color image) as an input and returns an `N x M x 3` array representing the corresponding vintage-filtered image.\n",
    "\n",
    "Test Case:\n",
    "```Python\n",
    ">> img = double(imread('sather.jpg'))/255;\n",
    ">> img_vintage = myVintageFilter(img);\n",
    ">> image(img_vintage)\n",
    "```\n",
    "![](E7_Lab7_10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5: Take it further: export an image you created (optional)\n",
    "\n",
    "It is very easy to save the images you produced with Python (and without using the figure\n",
    "editor). Assuming the array img represents the image you want to export, use the following\n",
    "command:\n",
    "\n",
    "```Python\n",
    ">> imwrite(img,'my_awesome_image.png');\n",
    "```\n",
    "\n",
    "It will create an image file called `'my_awesome_image.png'` in your working directory. You\n",
    "are not limited to the format PNG: with some more complex code, you can even create an\n",
    "animated GIF using the command imwrite!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 2: Land Use Changes\n",
    "\n",
    "Thanks to the satellites that have been orbiting the Earth for several decades now, it is\n",
    "possible to accurately classify land use (urban area, forested land, crops...) as well as its\n",
    "evolution throughout the years, known as land use change. For example, the images on\n",
    "Figure 4 illustrate the impact of deforestation in an area in the Brazilian state of Rondonia.\n",
    "\n",
    "Satelite image of a region in Brazil in 1985 | same region in 2015\n",
    "- | - \n",
    "![](E7_Lab7_13.jpg) | ![](E7_Lab7_14.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.1: Computing NDVI\n",
    "\n",
    "Write a function `myNDVI(img_RGB, img_NIR)`\n",
    "that takes two `N x M x 3` arrays as an input (`img_RGB` corresponds to the visible image and\n",
    "`img_NIR` corresponds to the near-infrared image) and returns an `N x M` array `NDVI` containing\n",
    "the NDVI calculated for each pixel.\n",
    "\n",
    "You will need to ensure that you do not divide by 0 while computing NDVI. Therefore,\n",
    "your function should modify both inputs such that pixels that were equal to 0 are now equal\n",
    "to the smallest non-zero red pixel value.\n",
    "\n",
    "Test Case:\n",
    "```Python\n",
    "aug_rgb = double(imread('brazil_1985_Aug_rgb.png'))/255;\n",
    "aug_nir = double(imread('brazil_1985_Aug_nir.png'))/255;\n",
    "ndvi = myNDVI(aug_rgb,aug_nir);\n",
    "imshow(ndvi);\n",
    "```\n",
    "\n",
    "![](E7_Lab7_15.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Classifying Vegetation\n",
    "\n",
    "To decide which pixels will be classified as vegetated, a threshold value has to be defined.\n",
    "If NDVI is greater than or equal to this threshold, it should be classified as vegetated. The\n",
    "choice of the threshold depends on the area you are analyzing, and has to be set manually.\n",
    "\n",
    "Write a function `vegArea(img_RGB, img_NIR, threshold, varargin)`\n",
    "that computes the total area of the image classified as vegetated, as determined by an input\n",
    "NDVI threshold, `threshold`.\n",
    "\n",
    "Your function should return the scalar double veg_area (total vegetated area) as well as\n",
    "the binary $NxM$ array `img_veg`: if the pixel (i,j) is classified as vegetated, `img_veg(i,j) = 1`;\n",
    "otherwise, `img_veg(i,j) = 0`.\n",
    "\n",
    "Notice that the last argument of the function is `varargin`. This indicates that the num-\n",
    "ber of inputs could vary, depending on what the user needs to run the function for. Your\n",
    "function should indeed be able to run with only the 3 inputs `img_RGB, img_NIR, threshold`\n",
    "as well as with an additional input `width` (representing the real-world total horizontal width\n",
    "of the region, expressed in km). In the first case, the resulting total vegetated area `veg_area`\n",
    "should be expressed as a percentage of the total surface area. In the second case, it should\n",
    "be expressed in km$^2$.\n",
    "\n",
    "**HINT**: First build the array `img_veg` using conditions on the NDVI. In the case where\n",
    "there is an additional input `width`, use it to compute the real-world area of one pixel.\n",
    "\n",
    "Test Case:\n",
    "```Python\n",
    ">> img_RGB = double(imread('brazil_1985_Aug_rgb.png'))/255;\n",
    ">> img_NIR = double(imread('brazil_1985_Aug_nir.png'))/255;\n",
    ">> [veg_area_percent, img_veg] = vegArea(img_RGB, img_NIR, 0.15);\n",
    ">> veg_area_percent\n",
    "\n",
    "veg_area_percent =\n",
    "84.0457\n",
    ">> [veg_area_km2, img_veg] = vegArea(img_RGB, img_NIR, 0.15, 88.9);\n",
    ">> veg_area_km2\n",
    "veg_area_km2 =\n",
    "4.7445e+03\n",
    ">> imshow(img_veg);\n",
    "```\n",
    "![](E7_Lab7_16.jpg)\n",
    "\n",
    "Test Case:\n",
    "```Python\n",
    ">> img_RGB = double(imread('brazil_2015_Aug_rgb.png'))/255;\n",
    ">> img_NIR = double(imread('brazil_2015_Aug_nir.png'))/255;\n",
    ">> [veg_area_percent, img_veg] = vegArea(img_RGB, img_NIR, 0.15);\n",
    ">> veg_area_percent\n",
    "\n",
    "veg_area_percent =\n",
    "45.1303\n",
    ">> [veg_area_km2, img_veg] = vegArea(img_RGB, img_NIR, 0.15, 88.9);\n",
    ">> veg_area_km2\n",
    "\n",
    "veg_area_km2 =\n",
    "2.5477e+03\n",
    ">> imshow(img_veg);\n",
    "```\n",
    "![](E7_Lab7_17.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Tracking Changes Over Time\n",
    "\n",
    "Write a function `vegChange(img_RGB1, img_NIR1, img_RGB2, img_NIR2, threshold, width)`\n",
    "that takes as inputs two sets of RGB and NIR images representing the same zone at different\n",
    "times and returns the total vegetation change (expressed in km$^2$) between these pictures,\n",
    "given a NDVI threshold and the real-world width of the region. Assume image 1 is the oldest\n",
    "one, so your function's output should return a positive value if there is more vegetation in\n",
    "image 2 than in image 1, and a negative value otherwise.\n",
    "\n",
    "Test Case:\n",
    "```Python\n",
    ">> img_RGB1 = double(imread('brazil_1985_Aug_rgb.png'))/255;\n",
    ">> img_NIR1 = double(imread('brazil_1985_Aug_nir.png'))/255;\n",
    ">> img_RGB2 = double(imread('brazil_2015_Aug_rgb.png'))/255;\n",
    ">> img_NIR2 = double(imread('brazil_2015_Aug_nir.png'))/255;\n",
    ">> veg_diff = vegChange(img_RGB1, img_NIR1, img_RGB2, img_NIR2,...\n",
    "0.15, 88.9);\n",
    ">> veg_diff\n",
    "\n",
    "veg_diff =\n",
    "-2.1968e+03\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Further Exploration\n",
    "\n",
    "You will also find two additional sets of images on bCourses that you can play with to check\n",
    "your functions: one of them illustrates the difference in snow cover in the Sierras between\n",
    "2003 and 2015. Though it's not a perfect measurement, we can gauge how snow cover has\n",
    "changed based on how much vegetation is visible (more snow cover means less vegetation is\n",
    "visible). Since annual snow melt is one of the primary sources of water in California, these\n",
    "images help illustrate the water storage issues that have affected California in the past few\n",
    "years. These images have a width of 151.13 km.\n",
    "\n",
    "The other set of images shows the development of crops in Saudi Arabia between 1984\n",
    "and 2015. The first set of images was taken before irrigation was allowed. Notice how much\n",
    "vegetation you see (it's a desert). The second image was taken after irrigation was made\n",
    "legal. The total horizontal width of these images is 30.48 km."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Cellular Automata\n",
    "\n",
    "A cellular automaton is an array of cells on a grid that evolves through a number of discrete\n",
    "time steps based upon a set of rules that depend on the state of neighboring cells. Even\n",
    "simple rules for deciding the \"on\" or \"off\" state of a cell can lead to complex and beautiful\n",
    "patterns. Cellular automata can be used to study the complexity found in nature, for example\n",
    "in snowflakes or mollusk shells.\n",
    "\n",
    "Let's consider the simplest class of cellular automata (known as elementary cellular au-\n",
    "tomata) in which an array contains a single row of N cells, $x(1)$ through $x(N)$, each of\n",
    "which has a \"state\" of either \"on\", which is represented numerically by 1, or \"off\", which\n",
    "is represented numerically by 0. The array then evolves in a series of discrete time steps,\n",
    "$t_0, t_1, t_2, \\dots, t_m$. At each time step $t_k$, the state of each cell $x_k(j)$ is determined based on its\n",
    "own state $x_{k-1}(j)$ in addition to the state of its two neighbors, $x_{k-1}(j - 1)$ and $x_{k-1}(j + 1)$,\n",
    "at the previous time step, $t_{k-1}$. The states of $x_{k-1}(j - 1)$, $x_{k-1}(j)$, and $x_k-1(j + 1)$ form\n",
    "3 binary digits (bits), which can correspond to a base-10 integer of 0 through 7, which we\n",
    "refer to as the \"neighbor state\". For example, a cell has a neighbor state of 7 (111) if in the\n",
    "previous time step it is on and both of its neighbors are on. If a cell is on but both of its\n",
    "neighbors are off, its neighbor state is 010, or 2. If a cell and both of its neighbors are off,\n",
    "then its neighbor state is 000, or 0.\n",
    "\n",
    "At each time step, each cell is set to either \"on\" or \"off\" based on its neighbor state (a\n",
    "base-10 integer 0 through 7), and a \"rule\". The rule is defined by an 8 bit binary number,\n",
    "with bits numbered 0 to 7. For example, if a cell has a neighbor state of 3, then the rule\n",
    "number would be used to determine its next state; for this example, the next state is 1 if\n",
    "the 3rd bit of the rule number is 1, or 0 if the 3rd bit of the rule is 0. Similarly, if a cell has\n",
    "a neighbor state of 5, the next state is 1 if the 5th bit of the rule is 1, or 0 if the 5th bit of\n",
    "the rule is 0.\n",
    "\n",
    "After M time steps, the entire \"history\" of the array can be displayed in an N x M\n",
    "matrix of 0s and 1s, or an image of N x M pixels, where \"on\" pixels are represented by\n",
    "white and \"off\" pixels are represented by black.\n",
    "Examples using 30 and 146 as a rule are given below. In these examples, we will use\n",
    "these representations for \"off\" and \"on\" states:\n",
    "\n",
    "| state                                                 | on    | o     |\n",
    "|-------------------------------------------------------|-------|-------|\n",
    "| value                                                 | 1     | 0     |\n",
    "| color                                                 | white | black |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boundary conditions**: The neighbor state can be computed for all cells on the grid, except\n",
    "those at the edge, which only have one neighbor. In order to determine the neighbor state\n",
    "for the cells on the edge, we must define boundary conditions. For this assignment, you will\n",
    "consider the cells that are off the grid to be permanently \"off\". This will be important when\n",
    "computing the first time step as well as any cells near the edges.\n",
    "\n",
    "**Examples: Rule 30 and Rule 146**\n",
    "The number 30 is 00011110 in binary and 146 is 10010010. At each time step, the new state\n",
    "of every cell is determined by its current neighbor state according to the following table:\n",
    "\n",
    "| state | \n",
    "|--------------------------------------------------------------------------|\n",
    "| neighbor state in base 10 | 7 | 6 | 5 | 4 | 3 | 2 | 1 | 0 |\n",
    "| neighbor state in binary | 111 | 110 |  101 | 100 | 011 | 010 | 001 | 000 |\n",
    "| new state using rule 30 | 0 | 0  | 0  |1 | 1 | 1 | 1 | 0 |\n",
    "| new state using rule 146 | 1 | 0 | 0 | 1 | 0 | 0 | 1 | 0 |\n",
    "\n",
    "Thus, for rule 30 if the neighbor state is 3 (011), the state of the current cell will be the 3$^{rd}$\n",
    "bit of rule 30, which is 1. For rule 146, if the neighbor state is 3, the state of the current cell\n",
    "will be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: myCellAuto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start out with a row which has a single \"on\" cell in the center and all the rest all \"off\".\n",
    "Here's what happens in the first three time steps of rule 30.\n",
    "\n",
    "| timestep | \n",
    "|--------------|---|---|---|---|---|---|---|\n",
    "| timestep, t0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 |\n",
    "| timestep, t1 | 0 | 0 | 1 | 1 | 1 | 0 | 0 |\n",
    "| timestep, t2 | 0 | 1 | 1 | 0 | 0 | 1 | 0 |\n",
    "| timestep, t3 | 1 | 1 | 0 | 1 | 1 | 1 | 1 |\n",
    "\n",
    "In Python we can convert a matrix of 0 and 1 into an image using `imshow`. If we run rule\n",
    "30 for a couple hundred time steps, an irregular pattern emerges. Shown below is the image\n",
    "produced by Python for the first 200 steps of rule 30 and rule 146.\n",
    "\n",
    "![](E7_Lab7_18.jpg)\n",
    "Figure 6: First 200 steps of rule 30\n",
    "\n",
    "Your job is to write a function `myCellAuto(rule,step)` that will generate these patterns.\n",
    "\n",
    "![](E7_Lab7_19.jpg)\n",
    "Figure 7: First 200 steps of rule 146\n",
    "\n",
    "Your function accepts two input arguments: the rule number in the form of a scalar `double`\n",
    "(rule) and the number of steps (`step`, also a scalar double). The output pattern is the\n",
    "resulting binary matrix (class double) of the cellular automaton. The first row (time step t0)\n",
    "is all black (all 0s) except for a single white (1) pixel at the center. This is then followed by\n",
    "a row for each time step. If there are N time steps, there should be N + 1 rows and 2 x N + 1\n",
    "columns in the image (N columns on both sides of the center column). So for example, the\n",
    "command `myCellAuto(30,200)` and `myCellAuto(146,200)` should produce the images in\n",
    "the figures, which each have 401 columns and 201 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready for the Oscars? (optional)\n",
    "\n",
    "In addition to being able to produce image files, it is possible to create movie files using\n",
    "Python. A movie is indeed nothing more than a succession of images displayed at a speed\n",
    "fast enough for our brains to process it as continuous.\n",
    "\n",
    "As a first attempt to conquer Hollywood, you can create a movie that will show the steps\n",
    "of the cellular automata you coded in the previous part. Starting from a black background,\n",
    "the movie should show the lines appear one by one, from top to bottom.\n",
    "\n",
    "A file named `createMovie.m` has been been provided on bCourses which you can use\n",
    "to create a movie of the evolution of your cellular automata. This file contains a nearly-\n",
    "complete function `createMovie(pattern)`,\n",
    "where `pattern` is an array as output by your previous function, `myCellAuto`. Once complete, the function will output `movie`, which will be of type `VideoWriter`, a specific format MATLAB uses to handle movie creation. The code will produce a movie file named\n",
    "`'myMovie.avi'` inside your working directory. You can then play the movie using your favorite video software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
